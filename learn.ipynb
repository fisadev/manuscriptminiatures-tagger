{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from utils import input_columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICTURE_SIZE = 100\n",
    "CHANNELS = 'rgb'\n",
    "\n",
    "INPUT_COLUMNS = input_columns_names(PICTURE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading data...')\n",
    "data = pd.read_pickle('./data/object_picture_sets/sword/dataframe_{}.pkl'.format(PICTURE_SIZE))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(samples, title=('label', 'file')):\n",
    "    for index, sample in samples.iterrows():\n",
    "        if title is not None:\n",
    "            if isinstance(title, str):\n",
    "                title = [title, ]\n",
    "            title_text = ', '.join(str(sample[title_field]) for title_field in title)\n",
    "            plt.title(title_text)\n",
    "\n",
    "        sample_as_grid = sample[INPUT_COLUMNS].values.reshape(len(CHANNELS), PICTURE_SIZE, PICTURE_SIZE).astype(np.float)\n",
    "        sample_as_grid = np.transpose(sample_as_grid, (1, 2, 0)) / 255\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(sample_as_grid, interpolation='nearest')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data[data.label == 1].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(data[data.label == 0].sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train = train.copy()\n",
    "test = test.copy()\n",
    "\n",
    "sets = (\n",
    "    ('train', train),\n",
    "    ('test', test),\n",
    ")\n",
    "\n",
    "for set_name, set_data in sets:\n",
    "    set_data.label.hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inputs(dataset):\n",
    "    return dataset[INPUT_COLUMNS].values.reshape(len(dataset), PICTURE_SIZE, PICTURE_SIZE, len(CHANNELS)) / 255\n",
    "\n",
    "def extract_outputs(dataset):\n",
    "    return dataset.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='tanh', kernel_regularizer=l2(0.01), input_shape=(PICTURE_SIZE, PICTURE_SIZE, len(CHANNELS))),\n",
    "    Conv2D(16, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Conv2D(16, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Conv2D(16, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Conv2D(16, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Conv2D(16, (3, 3), activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(1000, activation='tanh', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentator = ImageDataGenerator(\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    \n",
    "    vertical_flip=False,   \n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    ")\n",
    "augmentator.fit(extract_inputs(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    augmentator.flow(\n",
    "        extract_inputs(train), \n",
    "        extract_outputs(train),\n",
    "        batch_size=128,\n",
    "    ),\n",
    "    steps_per_epoch=len(train),\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(dataset):\n",
    "    dataset['model_output'] = model.predict(extract_inputs(dataset))\n",
    "    dataset['prediction'] = np.rint(dataset.model_output.values)\n",
    "    dataset['correct'] = dataset.prediction == dataset.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name, set_data in sets:\n",
    "    add_predictions(set_data)\n",
    "    \n",
    "    print('#' * 25, set_name, '#' * 25)\n",
    "    print('accuracy', accuracy_score(set_data.label, set_data.prediction))\n",
    "    print(classification_report(set_data.label, set_data.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_images(test[(test.correct) & (test.label == 1)].sample(3), title=['label', 'model_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(test[(~test.correct) & (test.label == 1)].sample(3), title=['label', 'model_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_images(test[(~test.correct) & (test.label == 0)].sample(3), title=['label', 'model_output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
